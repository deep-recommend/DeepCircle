{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4q2th0b6TQQ2",
        "outputId": "f749d372-a841-49cb-edec-7ae41f2b2a31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/sberbank-ai/sber-swap.git\n",
        "%cd sber-swap\n",
        "!wget -P ./arcface_model https://github.com/sberbank-ai/sber-swap/releases/download/arcface/backbone.pth\n",
        "!wget -P ./arcface_model https://github.com/sberbank-ai/sber-swap/releases/download/arcface/iresnet.py\n",
        "!wget -P ./insightface_func/models/antelope https://github.com/sberbank-ai/sber-swap/releases/download/antelope/glintr100.onnx\n",
        "!wget -P ./insightface_func/models/antelope https://github.com/sberbank-ai/sber-swap/releases/download/antelope/scrfd_10g_bnkps.onnx\n",
        "!wget -P ./weights https://github.com/sberbank-ai/sber-swap/releases/download/sber-swap-v2.0/G_unet_2blocks.pth\n",
        "!wget -P ./weights https://github.com/sberbank-ai/sber-swap/releases/download/super-res/10_net_G.pth"
      ],
      "metadata": {
        "id": "kG5RDcm_TTYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mxnet-cu101mkl\n",
        "!pip install onnxruntime-gpu==1.8\n",
        "!pip install insightface==0.2.1\n",
        "!pip install kornia==0.5.4"
      ],
      "metadata": {
        "id": "3Lrn4KcATVO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torch\n",
        "import time\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "from utils.inference.image_processing import crop_face, get_final_image, show_images\n",
        "from utils.inference.video_processing import read_video, get_target, get_final_video, add_audio_from_another_video, face_enhancement\n",
        "from utils.inference.core import model_inference\n",
        "\n",
        "from network.AEI_Net import AEI_Net\n",
        "from coordinate_reg.image_infer import Handler\n",
        "from insightface_func.i import Face_detect_crop\n",
        "from arcface_model.iresnet import iresnet100\n",
        "from models.pix2pix_model import Pix2PixModel\n",
        "from models.config_sr import TestOptions"
      ],
      "metadata": {
        "id": "mRWO2jR7TWno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app = Face_detect_crop(name='antelope', root='./insightface_func/models')\n",
        "app.prepare(ctx_id= 0, det_thresh=0.6, det_size=(640,640))\n",
        "\n",
        "G = AEI_Net(backbone='unet', num_blocks=2, c_id=512)\n",
        "G.eval()\n",
        "G.load_state_dict(torch.load('weights/G_unet_2blocks.pth', map_location=torch.device('cpu')))\n",
        "G = G.cuda()\n",
        "G = G.half()\n",
        "\n",
        "netArc = iresnet100(fp16=False)\n",
        "netArc.load_state_dict(torch.load('arcface_model/backbone.pth'))\n",
        "netArc=netArc.cuda()\n",
        "netArc.eval()\n",
        "\n",
        "handler = Handler('./coordinate_reg/model/2d106det', 0, ctx_id=0, det_size=640)\n",
        "\n",
        "use_sr = True\n",
        "if use_sr:\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    opt = TestOptions()\n",
        "    model = Pix2PixModel(opt)\n",
        "    model.netG.train()"
      ],
      "metadata": {
        "id": "sOCdLdxPTZxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_type = 'video'\n",
        "\n",
        "source_path = 'examples/images/jin.png'\n",
        "path_to_video = 'examples/videos/dj.mp4'\n",
        "\n",
        "source_full = cv2.imread(source_path)\n",
        "OUT_VIDEO_NAME = \"examples/results/result.mp4\"\n",
        "crop_size = 224\n",
        "\n",
        "try:\n",
        "    source = crop_face(source_full, app, crop_size)[0]\n",
        "    source = [source[:, :, ::-1]]\n",
        "    print(\"Everything is ok!\")\n",
        "except TypeError:\n",
        "    print(\"Bad source images\")\n",
        "\n",
        "if target_type == 'image':\n",
        "    target_full = cv2.imread(target_path)\n",
        "    full_frames = [target_full]\n",
        "else:\n",
        "    full_frames, fps = read_video(path_to_video)\n",
        "target = get_target(full_frames, app, crop_size)"
      ],
      "metadata": {
        "id": "Ux2lMfJ9Tc_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 40\n",
        "\n",
        "START_TIME = time.time()\n",
        "\n",
        "final_frames_list, crop_frames_list, full_frames, tfm_array_list = model_inference(\n",
        "    full_frames,\n",
        "    source,\n",
        "    target,\n",
        "    netArc,\n",
        "    G,\n",
        "    app,\n",
        "    set_target = False,\n",
        "    crop_size=crop_size,\n",
        "    BS=batch_size\n",
        ")\n",
        "\n",
        "if use_sr:\n",
        "  final_frames_list = face_enhancement(final_frames_list, model)\n",
        "\n",
        "if target_type == 'video':\n",
        "  get_final_video(\n",
        "      final_frames_list,\n",
        "      crop_frames_list,\n",
        "      full_frames,\n",
        "      tfm_array_list,\n",
        "      OUT_VIDEO_NAME,\n",
        "      fps,\n",
        "      handler\n",
        "  )\n",
        "\n",
        "  add_audio_from_another_video(path_to_video, OUT_VIDEO_NAME, \"audio\")\n",
        "\n",
        "  print(f'Full pipeline took {time.time() - START_TIME}')\n",
        "  print(f\"Video saved with path {OUT_VIDEO_NAME}\")\n",
        "else:\n",
        "  result = get_final_image(\n",
        "      final_frames_list,\n",
        "      crop_frames_list,\n",
        "      full_frames[0],\n",
        "      tfm_array_list,\n",
        "      handler\n",
        "  )\n",
        "  cv2.imwrite('examples/results/result.png', result)"
      ],
      "metadata": {
        "id": "f9Bh2degTntM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if target_type == 'image':\n",
        "  show_images(\n",
        "      [\n",
        "          source[0][:,:,::-1],\n",
        "          target_full,\n",
        "          result\n",
        "      ],\n",
        "      [\n",
        "          'Source Image',\n",
        "          'Target Image',\n",
        "          'Swapped Image'\n",
        "      ],\n",
        "      figsize=(20, 15)\n",
        "  )\n",
        "else:\n",
        "  video_file = open(OUT_VIDEO_NAME, \"r+b\").read()\n",
        "  video_url = f\"data:video/mp4;base64,{b64encode(video_file).decode()}\"\n",
        "  \n",
        "  HTML(f\"\"\"<video width={800} controls><source src=\"{video_url}\"></video>\"\"\")"
      ],
      "metadata": {
        "id": "cBMbSHBLTpzD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}